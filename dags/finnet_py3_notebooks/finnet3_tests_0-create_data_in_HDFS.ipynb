{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data for fullchain tests\n",
    "\n",
    "See: finnet-pipeline/docker-tests/fullchain/create_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add packages, append to `dags/requirements_py3.txt` and run `!pip3 install -r /usr/local/dags/requirements_py3.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install -r /usr/local/dags/requirements_py3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "### Stop current SC, test assumes no existing SC\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/usr/local/dags\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "\n",
    "from fncore_py3.utils.graph_specification import GraphSpec\n",
    "from fncore_py3.utils.spark_tools import get_spark_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/datasets/finnet\"\n",
    "DATA_FORMAT = \"parquet\"\n",
    "LOCAL_DATA_PATH = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "config = dict()\n",
    "config['SparkConfiguration'] = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation\",\"true\")\n",
    ")\n",
    "\n",
    "hiveFolderSep = \"__\"\n",
    "hiveDBName = \"default\"\n",
    "\n",
    "os.environ[\"GRAPH_DB\"] = \"\"\"bolt://neo4j:test@neo4j:7687\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get graph specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Purge folder\n",
    "# !hdfs dfs -rm -r $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = os.listdir(LOCAL_DATA_PATH)\n",
    "json_list = [k for k in data_list if re.match(r'.*\\.json$', k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with get_spark_context(config['SparkConfiguration']) as spark_ctx:\n",
    "    spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "    \n",
    "    # Read in the graph spec\n",
    "    for graph_spec in json_list:\n",
    "        with open(os.path.join(LOCAL_DATA_PATH, graph_spec), 'r') as f:\n",
    "            spec = json.load(f)\n",
    "            spec_model = GraphSpec.from_dict(spec)\n",
    "\n",
    "        graph_name = spec_model.name\n",
    "        table_names = [\n",
    "            spec.table_name for spec in\n",
    "            spec_model.node_lists + spec_model.edge_lists + spec_model.community_lists\n",
    "        ]\n",
    "\n",
    "        # Read the sample data and put into hdfs\n",
    "        for table in table_names:\n",
    "            filepath = 'file://' + \\\n",
    "                       os.path.join(LOCAL_DATA_PATH, str(table)) + \\\n",
    "                       '.csv'\n",
    "            data = spark.read.format('com.databricks.spark.csv')\\\n",
    "                              .option('header', 'true')\\\n",
    "                              .option('inferschema', 'false')\\\n",
    "                              .load(filepath)\n",
    "            \n",
    "            outdatapath = os.path.join(\n",
    "                DATA_PATH, graph_name, 'tables', table\n",
    "            )\n",
    "            data.write.format(DATA_FORMAT)\\\n",
    "                .mode(saveMode='overwrite')\\\n",
    "                .save(outdatapath)\n",
    "\n",
    "#             hivetablename = \".\".join([hiveDBName,hiveFolderSep.join([graph_name, 'tables', safe_table])])\n",
    "#             print(\"Writing {}\".format(hivetablename))\n",
    "#             data.write.format(DATA_FORMAT).mode(\"overwrite\").saveAsTable(hivetablename)\n",
    "            \n",
    "#     spark.sql(\"SHOW TABLES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<fncore_py3.utils.graph_specification.EdgeListSpec at 0x7faecf9c2eb8>,\n",
       " <fncore_py3.utils.graph_specification.EdgeListSpec at 0x7faecf9c2550>,\n",
       " <fncore_py3.utils.graph_specification.EdgeListSpec at 0x7faecf9b4a58>,\n",
       " <fncore_py3.utils.graph_specification.EdgeListSpec at 0x7faecf9d3828>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_model.edge_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_kind = spec_model.edge_lists[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toffee_s',\n",
       " [],\n",
       " [<fncore_py3.utils.graph_specification.ColumnSpec at 0x7faecf9d3400>])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edge_kind.source_column.name, edge_kind.source_labels, edge_kind.source_metadata_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src_meta'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_kind.source_metadata_columns[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toffee_t', ['is_target'], [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edge_kind.target_column.name, edge_kind.target_labels, edge_kind.target_metadata_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table_name': 'test_data_chocolate_node_list',\n",
       " 'name': 'chocolate nodes',\n",
       " 'labels': ['chocolate'],\n",
       " 'index_column': {'resolution_alias': 'chocolate',\n",
       "  'variable_definition': 'String',\n",
       "  'name': 'id',\n",
       "  'unrecognized-key': 'value',\n",
       "  'hidden': 'True'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"hidden\" field in json is ignored as designed\n",
    "assert{spec_model.node_lists[0].index_column.hidden == False}\n",
    "spec[\"node_lists\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_metadata_columns': [],\n",
       " 'edge_category': '27a69786-d1dd-4a9c-9982-34b2870245dd',\n",
       " 'grouping_columns': [{'use_as_label': False,\n",
       "   'name': 'group',\n",
       "   'friendly_name': 'common_group',\n",
       "   'hidden': False}],\n",
       " 'edge_labels': ['edge_group_type'],\n",
       " 'metadata_columns': [],\n",
       " 'index_column': {'variable_definition': 'String',\n",
       "  'resolution_alias': 'sweets',\n",
       "  'name': 'id'},\n",
       " 'name': 'toffee group nodes',\n",
       " 'labels': ['toffee_groups'],\n",
       " 'table_name': 'test_data_toffee_groups_list'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_model.community_lists[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finnet-pipeline (Python 3)",
   "language": "python",
   "name": "finnet-pipeline_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
